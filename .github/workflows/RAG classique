{
  "name": "RAG Classique V3.0 - Dense Retrieval + Reranking [PRODUCTION] HARDENED",
  "nodes": [
    {
      "parameters": {},
      "id": "sub-trigger",
      "name": "Sub-Workflow Trigger",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1,
      "position": [0, 400]
    },
    {
      "parameters": {
        "jsCode": "const input = $input.first().json;
const query = input.query;
const tenantId = input.tenant_id || 'default';
const traceId = input.trace_id || `tr-${Date.now()}`;

if (!query) {
  throw new Error('VALIDATION_ERROR: query is required');
}

return {
  query: String(query).substring(0, 2000).trim(),
  tenant_id: tenantId,
  trace_id: traceId,
  timestamp: new Date().toISOString()
};"
      },
      "id": "init-acl",
      "name": "Init & ACL",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [200, 400]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.LLM_API_URL || 'https://api.openai.com/v1/chat/completions' }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={
  "model": "{{ $vars.HYDE_MODEL || 'gpt-4o' }}",
  "messages": [
    {
      "role": "system",
      "content": "Tu es un expert en reformulation de requetes. Genere une reponse hypothetique detaillee a cette question. Cette reponse sera utilisee pour ameliorer la recherche semantique."
    },
    {
      "role": "user",
      "content": "{{ $json.query }}"
    }
  ],
  "temperature": 0.7,
  "max_tokens": 300
}",
        "options": {"timeout": 20000}
      },
      "id": "hyde-generator",
      "name": "HyDE Generator (Shield #4)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [400, 400],
      "credentials": {
        "httpHeaderAuth": {
          "id": "LLM_API_CREDENTIAL_ID",
          "name": "OpenAI API Key"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const initData = $node['Init & ACL'].json;
const hydeResponse = $json.choices?.[0]?.message?.content || initData.query;

return {
  ...initData,
  hyde_doc: hydeResponse,
  search_query: hydeResponse
};"
      },
      "id": "hyde-parser",
      "name": "HyDE Parser",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [600, 400]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.EMBEDDING_API_URL || 'https://api.openai.com/v1/embeddings' }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={
  "model": "text-embedding-3-large",
  "input": "{{ $json.search_query }}"
}",
        "options": {"timeout": 15000}
      },
      "id": "embedding-generator",
      "name": "Embedding Generator",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [800, 400],
      "credentials": {
        "httpHeaderAuth": {
          "id": "LLM_API_CREDENTIAL_ID",
          "name": "OpenAI API Key"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.PINECONE_URL }}/query",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={
  "vector": {{ JSON.stringify($json.data[0].embedding) }},
  "topK": 50,
  "includeMetadata": true,
  "filter": {
    "tenant_id": "{{ $node['HyDE Parser'].json.tenant_id }}",
    "is_obsolete": false
  }
}",
        "options": {"timeout": 15000}
      },
      "id": "pinecone-retrieval",
      "name": "Pinecone Retrieval (Shield #5)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [1000, 400],
      "credentials": {
        "httpHeaderAuth": {
          "id": "PINECONE_API_CREDENTIAL_ID",
          "name": "Pinecone API Key"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.COHERE_API_URL || 'https://api.cohere.ai/v1/rerank' }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={
  "model": "{{ $vars.RERANKER_MODEL || 'rerank-multilingual-v3.0' }}",
  "query": "{{ $node['HyDE Parser'].json.query }}",
  "documents": {{ JSON.stringify($json.matches.map(m => m.metadata.text || '')) }},
  "top_n": 5
}",
        "options": {"timeout": 15000}
      },
      "id": "cohere-reranker",
      "name": "Cohere Reranker (Shield #6)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [1200, 400],
      "credentials": {
        "httpHeaderAuth": {
          "id": "COHERE_API_CREDENTIAL_ID",
          "name": "Cohere API Key"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const hydeData = $node['HyDE Parser'].json;
const pineconeMatches = $node['Pinecone Retrieval (Shield #5)'].json.matches || [];
const rerankedResults = $json.results || [];

const topChunks = rerankedResults.slice(0, 5).map((result, idx) => {
  const originalMatch = pineconeMatches[result.index] || {};
  return {
    text: result.document?.text || originalMatch.metadata?.text || '',
    score: result.relevance_score || 0,
    source: originalMatch.metadata?.source_file || 'unknown',
    rank: idx + 1
  };
});

const contextWindow = topChunks.map((chunk, i) => 
  `[${i + 1}] Source: ${chunk.source}\
Contenu: ${chunk.text}`
).join('\
\
');

return {
  ...hydeData,
  top_chunks: topChunks,
  context_window: contextWindow,
  chunk_count: topChunks.length
};"
      },
      "id": "context-builder",
      "name": "Context Builder",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1400, 400]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.LLM_API_URL || 'https://api.openai.com/v1/chat/completions' }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={
  "model": "{{ $vars.DEFAULT_LLM_MODEL || 'gpt-4-turbo' }}",
  "messages": [
    {
      "role": "system",
      "content": "Tu es un assistant IA expert. Reponds a la question en te basant UNIQUEMENT sur le contexte fourni. Si le contexte ne contient pas l'information, dis-le clairement. Cite toujours tes sources [1], [2], etc."
    },
    {
      "role": "user",
      "content": "Contexte:\
{{ $json.context_window }}\
\
Question: {{ $json.query }}\
\
Reponds de maniere structuree et cite tes sources."
    }
  ],
  "temperature": 0.3,
  "max_tokens": 1500
}",
        "options": {"timeout": 30000}
      },
      "id": "llm-generator",
      "name": "LLM Generator (Shield #7)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [1600, 400],
      "credentials": {
        "httpHeaderAuth": {
          "id": "LLM_API_CREDENTIAL_ID",
          "name": "OpenAI API Key"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const contextData = $node['Context Builder'].json;
const llmResponse = $json.choices?.[0]?.message?.content || 'No answer generated';

return {
  status: 'SUCCESS',
  trace_id: contextData.trace_id,
  query: contextData.query,
  answer: llmResponse,
  sources: contextData.top_chunks.map(c => ({
    file: c.source,
    score: c.score,
    rank: c.rank
  })),
  metadata: {
    chunks_used: contextData.chunk_count,
    engine: 'QUALITATIVE',
    timestamp: new Date().toISOString()
  }
};"
      },
      "id": "response-formatter",
      "name": "Response Formatter",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1800, 400]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{ $vars.OTEL_COLLECTOR_URL || 'https://otel-collector.internal' }}/v1/traces",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={
  "traceId": "{{ $json.trace_id }}",
  "spanName": "rag_classique_complete",
  "status": "{{ $json.status }}",
  "attributes": {
    "chunks_used": {{ $json.metadata.chunks_used }}
  }
}",
        "options": {"timeout": 5000}
      },
      "id": "otel-export",
      "name": "OTEL Export (Shield #9)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [2000, 400],
      "onError": "continueErrorOutput"
    }
  ],
  "connections": {
    "Sub-Workflow Trigger": {
      "main": [[{"node": "Init & ACL", "type": "main", "index": 0}]]
    },
    "Init & ACL": {
      "main": [[{"node": "HyDE Generator (Shield #4)", "type": "main", "index": 0}]]
    },
    "HyDE Generator (Shield #4)": {
      "main": [[{"node": "HyDE Parser", "type": "main", "index": 0}]]
    },
    "HyDE Parser": {
      "main": [[{"node": "Embedding Generator", "type": "main", "index": 0}]]
    },
    "Embedding Generator": {
      "main": [[{"node": "Pinecone Retrieval (Shield #5)", "type": "main", "index": 0}]]
    },
    "Pinecone Retrieval (Shield #5)": {
      "main": [[{"node": "Cohere Reranker (Shield #6)", "type": "main", "index": 0}]]
    },
    "Cohere Reranker (Shield #6)": {
      "main": [[{"node": "Context Builder", "type": "main", "index": 0}]]
    },
    "Context Builder": {
      "main": [[{"node": "LLM Generator (Shield #7)", "type": "main", "index": 0}]]
    },
    "LLM Generator (Shield #7)": {
      "main": [[{"node": "Response Formatter", "type": "main", "index": 0}]]
    },
    "Response Formatter": {
      "main": [[{"node": "OTEL Export (Shield #9)", "type": "main", "index": 0}]]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "saveManualExecutions": true,
    "callerPolicy": "workflowsFromSameOwner"
  },
  "active": true,
  "meta": {
    "instanceId": "production-sota-2026"
  }
}
